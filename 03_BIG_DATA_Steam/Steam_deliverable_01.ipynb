{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "steam = spark.read.json('s3://full-stack-bigdata-datasets/Big_Data/Project_Steam/steam_game_output.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam.select('data').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam.count())\n",
    "print(steam.select('id').distinct().count())\n",
    "print(steam.select('data.appid').distinct().count())\n",
    "print(steam.filter(F.col('data.appid') != F.col('id')).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### \"id\" initial column contains the same info that data[\"appid\"]. We can dive one level into the nested data frame and make our analysis on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_2 = steam.select('data')\n",
    "steam_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Which publisher has released the most games on Steam?\n",
    "#  Grouping by publisher and counting occurences.\n",
    "\n",
    "steam_2.groupBy('data.publisher').count().orderBy('count',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 What are the best rated games ?\n",
    "#  Absolute count of positive rates per game\n",
    "\n",
    "steam_2.orderBy(\"data.positive\",ascending=False).select(\"data.name\",\"data.positive\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Proportionally most liked games (among rated + 100000 times)\n",
    "\n",
    "preprocess_rating = steam_2 \\\n",
    "    .withColumn(\"int_positive\", F.col(\"data.positive\").cast(\"int\")) \\\n",
    "    .withColumn(\"int_negative\", F.col(\"data.negative\").cast(\"int\")) \\\n",
    "    .withColumn(\"prop_rating\", F.col(\"int_positive\")/(F.col(\"int_positive\")+F.col(\"int_negative\")))\n",
    "preprocess_rating.show(5)\n",
    "\n",
    "prop_rating = preprocess_rating \\\n",
    "    .filter((F.col(\"int_positive\")+F.col(\"int_negative\")) > 100_000) \\\n",
    "    .orderBy(\"prop_rating\", ascending=False) \\\n",
    "    .select(\"data.name\", \"prop_rating\")\n",
    "prop_rating.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Which years with more releases? Releases during COVID (2020) ?\n",
    "#  Extracting year from original dataset and counting occurences.\n",
    "\n",
    "release_year = steam_2.withColumn(\"release_year\", F.substring(F.col(\"data.release_date\"), 1, 4)).select(\"release_year\")\n",
    "print(release_year.show(5))\n",
    "release_year.groupBy('release_year').count().orderBy('count',ascending=False).show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 How are the prizes distributed? Are there many games with a discount?\n",
    "#  Groupby price and count occurences // count games with a discount\n",
    "\n",
    "preprocess_price = steam_2 \\\n",
    "    .withColumn(\"price_float\", F.col(\"data.price\").cast(\"int\")) \\\n",
    "    .withColumn(\"discount_float\", F.col(\"data.discount\").cast(\"int\")) \\\n",
    "    .select(\"data.name\",\"price_float\",\"discount_float\")\n",
    "preprocess_price.show(3)\n",
    "\n",
    "print(preprocess_price.groupBy('price_float').count().orderBy('count',ascending=False).show(20))\n",
    "\n",
    "print(preprocess_price.filter(F.col(\"discount_float\")> 0).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 What are the most represented languages?\n",
    "#  Explode languages for each game and count occurences\n",
    "\n",
    "language_count = steam_2 \\\n",
    "    .withColumn(\"languages_array\", F.split(\"data.languages\", \", \")) \\\n",
    "    .select(\"data.name\", \"languages_array\")\n",
    "language_count.show(5)\n",
    "\n",
    "exploded_languages = language_count.withColumn(\"language\", F.explode(language_count[\"languages_array\"]))\n",
    "exploded_languages.groupBy(\"language\").count().orderBy('count',ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 How many games prohibited for children under 16/18?\n",
    "#  Delete non usable info, converting to int, filter to more than 16yrs required age\n",
    "\n",
    "steam_2.groupBy('data.required_age').count().orderBy('count',ascending=False).show(25)\n",
    "\n",
    "values_to_delete = [\"21+\", \"7+\",\"MA 15+\"]\n",
    "prep_prohibited_games = steam_2.filter(~F.col(\"data.required_age\").isin(values_to_delete))\n",
    "prep_prohibited_games.count()\n",
    "\n",
    "prep_prohibited_games = prep_prohibited_games \\\n",
    "    .withColumn(\"int_required_age\", F.col(\"data.required_age\").cast(\"int\")) \\\n",
    "    .filter(F.col(\"int_required_age\") >= 16) \\\n",
    "    .select(\"int_required_age\")\n",
    "\n",
    "prohibited_games = prep_prohibited_games.groupBy('int_required_age').count().orderBy('count',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genres analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most represented genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField\n",
    "# from typing import List, Dict, Generator, Union, Callable\n",
    "\n",
    "# def walkSchema(schema: Union[StructType, StructField]) -> Generator[str, None, None]:\n",
    "#     \"\"\"Explores a PySpark schema:\n",
    "    \n",
    "#     schema: StructType | StructField\n",
    "    \n",
    "#     Yield\n",
    "#     -----\n",
    "#     A generator of strings, the name of each field in the schema\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # we define a function _walk that produces a string generator from\n",
    "#     # a dictionnary \"schema_dct\", and a string \"prefix\"\n",
    "#     def _walk(schema_dct: Dict['str', Union['str', list, dict]],\n",
    "#               prefix: str = \"\") -> Generator[str, None, None]:\n",
    "#         assert isinstance(prefix, str), \"prefix should be a string\" # check if prefix is a string\n",
    "        \n",
    "#         # this function returns \"name\" if there's no prefix and \"prefix.name\" if prefix exists\n",
    "#         fullName: Callable[str, str] = lambda name: ( \n",
    "#             name if not prefix else f\"{prefix}.{name}\")\n",
    "        \n",
    "#         # we get the next name one level lower from the dictionnary\n",
    "#         name = schema_dct.get('name', '')\n",
    "        \n",
    "#         # if the type is struct then we search for the fields key\n",
    "#         # if fields is there we apply the function again and dig one level deeper in\n",
    "#         # the schema and set a prefix\n",
    "#         if schema_dct['type'] == 'struct':\n",
    "#             assert 'fields' in schema_dct, (\n",
    "#                 \"It's a StructType, we should have some fields\")\n",
    "#             for field in schema_dct['fields']:\n",
    "#                 yield from _walk(field, prefix=prefix)\n",
    "#         # if we have a dict type and we can't find fields then we\n",
    "#         # dig one level deeper and apply the _walk function again\n",
    "#         elif isinstance(schema_dct['type'], dict):\n",
    "#             assert 'fields' not in schema_dct, (\n",
    "#                 \"We're missing some keys here\")\n",
    "#             yield from _walk(schema_dct['type'], prefix=fullName(name))\n",
    "#         # If we finally reached the end and found a name we yield the full name\n",
    "#         elif name:\n",
    "#             yield fullName(name)\n",
    "    \n",
    "#     yield from _walk(schema.jsonValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_names = walkSchema(steam.schema)\n",
    "\n",
    "# for col_name in walkSchema(steam.schema):\n",
    "#   print(col_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
